{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"300features_40minwords_10context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x219d2718780>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"flower\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test =pd.read_csv(\"testData.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "    #remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    #remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    \n",
    "    #convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    #optionally remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "    #return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    #Remove HTML\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    \n",
    "    # convert tp lower case, split into individual words\n",
    "    words = letters_only.split().lower()\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n",
      "Review 0 of 25000\n",
      "Review 1000 of 25000\n",
      "Review 2000 of 25000\n",
      "Review 3000 of 25000\n",
      "Review 4000 of 25000\n",
      "Review 5000 of 25000\n",
      "Review 6000 of 25000\n",
      "Review 7000 of 25000\n",
      "Review 8000 of 25000\n",
      "Review 9000 of 25000\n",
      "Review 10000 of 25000\n",
      "Review 11000 of 25000\n",
      "Review 12000 of 25000\n",
      "Review 13000 of 25000\n",
      "Review 14000 of 25000\n",
      "Review 15000 of 25000\n",
      "Review 16000 of 25000\n",
      "Review 17000 of 25000\n",
      "Review 18000 of 25000\n",
      "Review 19000 of 25000\n",
      "Review 20000 of 25000\n",
      "Review 21000 of 25000\n",
      "Review 22000 of 25000\n",
      "Review 23000 of 25000\n",
      "Review 24000 of 25000\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "for review in train[\"review\"]:\n",
    "    clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "clean_test_reviews = []\n",
    "for review in test[\"review\"]:\n",
    "    clean_test_reviews.append( review_to_wordlist( review, \\\n",
    "        remove_stopwords=True ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-c5292321ebbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting a random forest to labeled training data...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrainDataVecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sentiment\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Test & extract results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "print (\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit( trainDataVecs, train[\"sentiment\"] )\n",
    "\n",
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureVec = np.zeros((num_features,),dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index2word_set = set(model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'famously',\n",
       " 'filtered',\n",
       " 'sickly',\n",
       " 'claims',\n",
       " 'percentage',\n",
       " 'comforting',\n",
       " 'props',\n",
       " 'punch',\n",
       " 'delve',\n",
       " 'saturated',\n",
       " 'precursor',\n",
       " 'refused',\n",
       " 'conduct',\n",
       " 'wards',\n",
       " 'gentle',\n",
       " 'hottie',\n",
       " 'proposes',\n",
       " 'engineering',\n",
       " 'own',\n",
       " 'sea',\n",
       " 'forced',\n",
       " 'classics',\n",
       " 'images',\n",
       " 'serbian',\n",
       " 'contestant',\n",
       " 'problems',\n",
       " 'spotted',\n",
       " 'removed',\n",
       " 'aishwarya',\n",
       " 'creaky',\n",
       " 'bluntly',\n",
       " 'torturing',\n",
       " 'captain',\n",
       " 'nearby',\n",
       " 'brutally',\n",
       " 'cynic',\n",
       " 'harmful',\n",
       " 'release',\n",
       " 'explicit',\n",
       " 'underwear',\n",
       " 'mission',\n",
       " 'belonged',\n",
       " 'rathbone',\n",
       " 'photographer',\n",
       " 'ally',\n",
       " 'benton',\n",
       " 'tearful',\n",
       " 'ballet',\n",
       " 'techno',\n",
       " 'introduce',\n",
       " 'trousers',\n",
       " 'neeson',\n",
       " 'unity',\n",
       " 'stomping',\n",
       " 'spark',\n",
       " 'heck',\n",
       " 'captivate',\n",
       " 'incessant',\n",
       " 'decision',\n",
       " 'inexplicably',\n",
       " 'employ',\n",
       " 'rag',\n",
       " 'through',\n",
       " 'begin',\n",
       " 'hostile',\n",
       " 'disc',\n",
       " 'anil',\n",
       " 'action',\n",
       " 'bitterly',\n",
       " 'panties',\n",
       " 'career',\n",
       " 'bettie',\n",
       " 'fosse',\n",
       " 'sketches',\n",
       " 'assuming',\n",
       " 'slashers',\n",
       " 'kisna',\n",
       " 'reacted',\n",
       " 'lampoon',\n",
       " 'moderately',\n",
       " 'goofy',\n",
       " 'thirties',\n",
       " 'bulb',\n",
       " 'castles',\n",
       " 'scrap',\n",
       " 'bucks',\n",
       " 'gimmick',\n",
       " 'you',\n",
       " 'choreography',\n",
       " 'jose',\n",
       " 'novarro',\n",
       " 'futurama',\n",
       " 'unbearably',\n",
       " 'preventing',\n",
       " 'voyeurism',\n",
       " 'ins',\n",
       " 'flynn',\n",
       " 'dumped',\n",
       " 'caf',\n",
       " 'colourful',\n",
       " 'babble',\n",
       " 'maine',\n",
       " 'generator',\n",
       " 'contest',\n",
       " 'jacqueline',\n",
       " 'unborn',\n",
       " 'doomsday',\n",
       " 'mcgavin',\n",
       " 'difference',\n",
       " 'puns',\n",
       " 'tug',\n",
       " 'tomei',\n",
       " 'flashlight',\n",
       " 'carter',\n",
       " 'grieving',\n",
       " 'continental',\n",
       " 'severely',\n",
       " 'redeemable',\n",
       " 'hapless',\n",
       " 'rescue',\n",
       " 'admits',\n",
       " 'cosby',\n",
       " 'affection',\n",
       " 'exposed',\n",
       " 'truthful',\n",
       " 'deserve',\n",
       " 'comedians',\n",
       " 'turgid',\n",
       " 'noteworthy',\n",
       " 'whore',\n",
       " 'coup',\n",
       " 'neglects',\n",
       " 'harsh',\n",
       " 'turturro',\n",
       " 'boorman',\n",
       " 'sail',\n",
       " 'campaign',\n",
       " 'comics',\n",
       " 'singers',\n",
       " 'graced',\n",
       " 'unusual',\n",
       " 'nails',\n",
       " 'federal',\n",
       " 'aircraft',\n",
       " 'winona',\n",
       " 'steinbeck',\n",
       " 'arden',\n",
       " 'handicapped',\n",
       " 'jew',\n",
       " 'religions',\n",
       " 'da',\n",
       " 'centerpiece',\n",
       " 'sophisticated',\n",
       " 'rehash',\n",
       " 'cost',\n",
       " 'directs',\n",
       " 'categories',\n",
       " 'effective',\n",
       " 'significant',\n",
       " 'declare',\n",
       " 'stunning',\n",
       " 'popcorn',\n",
       " 'fenton',\n",
       " 'walking',\n",
       " 'parodies',\n",
       " 'bath',\n",
       " 'wwi',\n",
       " 'duet',\n",
       " 'albeit',\n",
       " 'uninvolving',\n",
       " 'superstars',\n",
       " 'honest',\n",
       " 'propelled',\n",
       " 'chews',\n",
       " 'rocked',\n",
       " 'gandhi',\n",
       " 'positions',\n",
       " 'beaten',\n",
       " 'felt',\n",
       " 'rifle',\n",
       " 'pawn',\n",
       " 'aftermath',\n",
       " 'perverted',\n",
       " 'harmed',\n",
       " 'pulp',\n",
       " 'fit',\n",
       " 'cathartic',\n",
       " 'correctly',\n",
       " 'houston',\n",
       " 'portions',\n",
       " 'scholars',\n",
       " 'charmingly',\n",
       " 'christensen',\n",
       " 'fury',\n",
       " 'lili',\n",
       " 'wwii',\n",
       " 'improvise',\n",
       " 'rand',\n",
       " 'main',\n",
       " 'lights',\n",
       " 'erotic',\n",
       " 'needle',\n",
       " 'colour',\n",
       " 'lifelong',\n",
       " 'drivel',\n",
       " 'specifics',\n",
       " 'erin',\n",
       " 'brits',\n",
       " 'tender',\n",
       " 'encountering',\n",
       " 'bookstore',\n",
       " 'complicated',\n",
       " 'christine',\n",
       " 'generic',\n",
       " 'rife',\n",
       " 'bend',\n",
       " 'southerner',\n",
       " 'abusive',\n",
       " 'harbor',\n",
       " 'quotable',\n",
       " 'celebrating',\n",
       " 'protection',\n",
       " 'caricature',\n",
       " 'arguing',\n",
       " 'titles',\n",
       " 'disasters',\n",
       " 'moods',\n",
       " 'dancer',\n",
       " 'melvyn',\n",
       " 'cleared',\n",
       " 'reed',\n",
       " 'secretary',\n",
       " 'hell',\n",
       " 'bravo',\n",
       " 'bumping',\n",
       " 'merrill',\n",
       " 'deliver',\n",
       " 'disrespectful',\n",
       " 'egos',\n",
       " 'fatty',\n",
       " 'flicks',\n",
       " 'worker',\n",
       " 'salma',\n",
       " 'diabolical',\n",
       " 'hastings',\n",
       " 'realm',\n",
       " 'crumbling',\n",
       " 'bastards',\n",
       " 'structure',\n",
       " 'poison',\n",
       " 'gotten',\n",
       " 'displaying',\n",
       " 'preferred',\n",
       " 'concluding',\n",
       " 'death',\n",
       " 'possessed',\n",
       " 'hatred',\n",
       " 'four',\n",
       " 'yesterday',\n",
       " 'lake',\n",
       " 'apology',\n",
       " 'avoids',\n",
       " 'blown',\n",
       " 'recommendation',\n",
       " 'plucky',\n",
       " 'account',\n",
       " 'irs',\n",
       " 'confess',\n",
       " 'seeming',\n",
       " 'kern',\n",
       " 'disclaimer',\n",
       " 'kerrigan',\n",
       " 'shifted',\n",
       " 'poppins',\n",
       " 'half',\n",
       " 'further',\n",
       " 'hank',\n",
       " 'gambler',\n",
       " 'rival',\n",
       " 'ringo',\n",
       " 'mismatched',\n",
       " 'vocal',\n",
       " 'chock',\n",
       " 'socio',\n",
       " 'canon',\n",
       " 'terry',\n",
       " 'here',\n",
       " 'apostle',\n",
       " 'hunted',\n",
       " 'remake',\n",
       " 'eggs',\n",
       " 'tons',\n",
       " 'below',\n",
       " 'historic',\n",
       " 'conclude',\n",
       " 'ignoring',\n",
       " 'plates',\n",
       " 'horsemen',\n",
       " 'midway',\n",
       " 'endlessly',\n",
       " 'rental',\n",
       " 'outlaws',\n",
       " 'redemption',\n",
       " 'overworked',\n",
       " 'identities',\n",
       " 'choking',\n",
       " 'wooden',\n",
       " 'realism',\n",
       " 'weigh',\n",
       " 'keeper',\n",
       " 'bumbling',\n",
       " 'rocker',\n",
       " 'classical',\n",
       " 'clich',\n",
       " 'nameless',\n",
       " 'theme',\n",
       " 'nominated',\n",
       " 'sister',\n",
       " 'moody',\n",
       " 'dudes',\n",
       " 'pasted',\n",
       " 'eyeballs',\n",
       " 'bass',\n",
       " 'sassy',\n",
       " 'inaccurate',\n",
       " 'spared',\n",
       " 'emerging',\n",
       " 'sperm',\n",
       " 'band',\n",
       " 'indeed',\n",
       " 'spirituality',\n",
       " 'rappers',\n",
       " 'belief',\n",
       " 'buzz',\n",
       " 'unfortunate',\n",
       " 'outrageously',\n",
       " 'heiress',\n",
       " 'fraction',\n",
       " 'scrappy',\n",
       " 'showing',\n",
       " 'newcomer',\n",
       " 'drooling',\n",
       " 'tarzan',\n",
       " 'manhattan',\n",
       " 'scarface',\n",
       " 'revel',\n",
       " 'airline',\n",
       " 'greer',\n",
       " 'pupils',\n",
       " 'egg',\n",
       " 'chainsaw',\n",
       " 'trappings',\n",
       " 'desires',\n",
       " 'sheriff',\n",
       " 'repressed',\n",
       " 'magnolia',\n",
       " 'equation',\n",
       " 'procedure',\n",
       " 'linda',\n",
       " 'minus',\n",
       " 'sensitive',\n",
       " 'imitations',\n",
       " 'tell',\n",
       " 'unleash',\n",
       " 'amused',\n",
       " 'swearing',\n",
       " 'public',\n",
       " 'enter',\n",
       " 'wacky',\n",
       " 'minotaur',\n",
       " 'herbie',\n",
       " 'mankiewicz',\n",
       " 'gere',\n",
       " 'coronation',\n",
       " 'hunchback',\n",
       " 'absorbed',\n",
       " 'geeky',\n",
       " 'party',\n",
       " 'scorsese',\n",
       " 'toback',\n",
       " 'carrier',\n",
       " 'dc',\n",
       " 'advised',\n",
       " 'hosts',\n",
       " 'happier',\n",
       " 'informer',\n",
       " 'ogre',\n",
       " 'additions',\n",
       " 'warrior',\n",
       " 'guinea',\n",
       " 'elders',\n",
       " 'lindy',\n",
       " 'cliches',\n",
       " 'saget',\n",
       " 'angeles',\n",
       " 'writings',\n",
       " 'irony',\n",
       " 'rather',\n",
       " 'scarce',\n",
       " 'honestly',\n",
       " 'lohan',\n",
       " 'spouses',\n",
       " 'katherine',\n",
       " 'introduction',\n",
       " 'criticized',\n",
       " 'kiddies',\n",
       " 'prisons',\n",
       " 'akshay',\n",
       " 'zack',\n",
       " 'armored',\n",
       " 'complexity',\n",
       " 'captured',\n",
       " 'preferably',\n",
       " 'compromised',\n",
       " 'awards',\n",
       " 'princess',\n",
       " 'cared',\n",
       " 'spectacle',\n",
       " 'sights',\n",
       " 'old',\n",
       " 'brutality',\n",
       " 'patricia',\n",
       " 'financed',\n",
       " 'guidelines',\n",
       " 'settlers',\n",
       " 'turkish',\n",
       " 'briggs',\n",
       " 'hooray',\n",
       " 'mussolini',\n",
       " 'emmy',\n",
       " 'hurt',\n",
       " 'icon',\n",
       " 'drops',\n",
       " 'benicio',\n",
       " 'deeply',\n",
       " 'womanizer',\n",
       " 'dixon',\n",
       " 'atlantic',\n",
       " 'directed',\n",
       " 'squeeze',\n",
       " 'hawaiian',\n",
       " 'heartwarming',\n",
       " 'casey',\n",
       " 'mannerisms',\n",
       " 'oddball',\n",
       " 'stalks',\n",
       " 'chamber',\n",
       " 'both',\n",
       " 'caliber',\n",
       " 'corps',\n",
       " 'mourning',\n",
       " 'amendment',\n",
       " 'alternately',\n",
       " 'undone',\n",
       " 'professionalism',\n",
       " 'germans',\n",
       " 'management',\n",
       " 'cobra',\n",
       " 'bolivia',\n",
       " 'filmography',\n",
       " 'origins',\n",
       " 'eponymous',\n",
       " 'mart',\n",
       " 'apes',\n",
       " 'positive',\n",
       " 'gannon',\n",
       " 'deluise',\n",
       " 'righteous',\n",
       " 'beats',\n",
       " 'li',\n",
       " 'fractured',\n",
       " 'painter',\n",
       " 'bit',\n",
       " 'accidental',\n",
       " 'continue',\n",
       " 'developments',\n",
       " 'grenade',\n",
       " 'mcgee',\n",
       " 'episodes',\n",
       " 'speak',\n",
       " 'abbey',\n",
       " 'reproduce',\n",
       " 'population',\n",
       " 'hues',\n",
       " 'marcus',\n",
       " 'killing',\n",
       " 'checks',\n",
       " 'romantic',\n",
       " 'whisper',\n",
       " 'diet',\n",
       " 'tom',\n",
       " 'fallon',\n",
       " 'don',\n",
       " 'plethora',\n",
       " 'bathroom',\n",
       " 'questioned',\n",
       " 'hecht',\n",
       " 'selma',\n",
       " 'paying',\n",
       " 'reprehensible',\n",
       " 'nearly',\n",
       " 'tends',\n",
       " 'station',\n",
       " 'profit',\n",
       " 'chopra',\n",
       " 'unsuccessfully',\n",
       " 'riches',\n",
       " 'rebirth',\n",
       " 'chen',\n",
       " 'recognised',\n",
       " 'emerges',\n",
       " 'friendships',\n",
       " 'intriguing',\n",
       " 'corny',\n",
       " 'varying',\n",
       " 'deeper',\n",
       " 'away',\n",
       " 'accomplished',\n",
       " 'suck',\n",
       " 'erotica',\n",
       " 'eyebrows',\n",
       " 'restricted',\n",
       " 'kellogg',\n",
       " 'smokes',\n",
       " 'brian',\n",
       " 'petulia',\n",
       " 'trace',\n",
       " 'pope',\n",
       " 'thou',\n",
       " 'wants',\n",
       " 'samir',\n",
       " 'elegantly',\n",
       " 'manchu',\n",
       " 'accuses',\n",
       " 'birds',\n",
       " 'russ',\n",
       " 'exclusive',\n",
       " 'jawed',\n",
       " 'torture',\n",
       " 'fakes',\n",
       " 'dallas',\n",
       " 'serials',\n",
       " 'congress',\n",
       " 'receive',\n",
       " 'mansion',\n",
       " 'rejected',\n",
       " 'protecting',\n",
       " 'minute',\n",
       " 'discipline',\n",
       " 'nukie',\n",
       " 'boyer',\n",
       " 'therefor',\n",
       " 'characterized',\n",
       " 'boost',\n",
       " 'ordering',\n",
       " 'belle',\n",
       " 'heterosexual',\n",
       " 'mcg',\n",
       " 'capote',\n",
       " 'stilted',\n",
       " 'corruption',\n",
       " 'wine',\n",
       " 'recap',\n",
       " 'factory',\n",
       " 'overacted',\n",
       " 'anything',\n",
       " 'erica',\n",
       " 'delon',\n",
       " 'rely',\n",
       " 'toby',\n",
       " 'chooses',\n",
       " 'increased',\n",
       " 'centuries',\n",
       " 'chores',\n",
       " 'rises',\n",
       " 'talking',\n",
       " 'satire',\n",
       " 'culprit',\n",
       " 'mediocrity',\n",
       " 'couldn',\n",
       " 'activities',\n",
       " 'mockery',\n",
       " 'tito',\n",
       " 'manual',\n",
       " 'warlord',\n",
       " 'ahmed',\n",
       " 'tenant',\n",
       " 'vacuum',\n",
       " 'royalty',\n",
       " 'spread',\n",
       " 'pitcher',\n",
       " 'otto',\n",
       " 'showers',\n",
       " 'stood',\n",
       " 'examples',\n",
       " 'superior',\n",
       " 'contender',\n",
       " 'oprah',\n",
       " 'cinema',\n",
       " 'bimbo',\n",
       " 'visibly',\n",
       " 'ghouls',\n",
       " 'appreciating',\n",
       " 'union',\n",
       " 'disappointments',\n",
       " 'desirable',\n",
       " 'failings',\n",
       " 'pandora',\n",
       " 'geez',\n",
       " 'immortal',\n",
       " 'minghella',\n",
       " 'roads',\n",
       " 'resort',\n",
       " 'cartoons',\n",
       " 'lizzie',\n",
       " 'hunger',\n",
       " 'normally',\n",
       " 'dell',\n",
       " 'temple',\n",
       " 'cabin',\n",
       " 'deals',\n",
       " 'davies',\n",
       " 'spoil',\n",
       " 'some',\n",
       " 'county',\n",
       " 'strangler',\n",
       " 'previews',\n",
       " 'hundreds',\n",
       " 'jared',\n",
       " 'roswell',\n",
       " 'maybe',\n",
       " 'kirk',\n",
       " 'guise',\n",
       " 'misunderstandings',\n",
       " 'lesser',\n",
       " 'calculated',\n",
       " 'steiger',\n",
       " 'b',\n",
       " 'durante',\n",
       " 'keeler',\n",
       " 'veritable',\n",
       " 'grodin',\n",
       " 'women',\n",
       " 'sliding',\n",
       " 'goblins',\n",
       " 'atkins',\n",
       " 'understandable',\n",
       " 'danza',\n",
       " 'underplayed',\n",
       " 'spoilers',\n",
       " 'respective',\n",
       " 'slant',\n",
       " 'instance',\n",
       " 'advice',\n",
       " 'girl',\n",
       " 'cause',\n",
       " 'versatility',\n",
       " 'jets',\n",
       " 'uncle',\n",
       " 'unravel',\n",
       " 'walsh',\n",
       " 'minds',\n",
       " 'colin',\n",
       " 'contributions',\n",
       " 'pulled',\n",
       " 'chuckles',\n",
       " 'embarrassment',\n",
       " 'sweetheart',\n",
       " 'freud',\n",
       " 'programmer',\n",
       " 'uptight',\n",
       " 'communism',\n",
       " 'finest',\n",
       " 'veers',\n",
       " 'barren',\n",
       " 'view',\n",
       " 'delusions',\n",
       " 'busting',\n",
       " 'relates',\n",
       " 'atmosphere',\n",
       " 'bike',\n",
       " 'remain',\n",
       " 'www',\n",
       " 'divorced',\n",
       " 'choosing',\n",
       " 'mama',\n",
       " 'nuts',\n",
       " 'default',\n",
       " 'screamed',\n",
       " 'occurs',\n",
       " 'hands',\n",
       " 'melvin',\n",
       " 'hugh',\n",
       " 'unscathed',\n",
       " 'reliance',\n",
       " 'hutch',\n",
       " 'violence',\n",
       " 'arbuckle',\n",
       " 'entertained',\n",
       " 'entertainer',\n",
       " 'belgian',\n",
       " 'overtones',\n",
       " 'crass',\n",
       " 'predictable',\n",
       " 'seeing',\n",
       " 'flair',\n",
       " 'filmmaking',\n",
       " 'commenting',\n",
       " 'weaponry',\n",
       " 'hush',\n",
       " 'zombi',\n",
       " 'fooling',\n",
       " 'parachute',\n",
       " 'quarry',\n",
       " 'trademark',\n",
       " 'desi',\n",
       " 'est',\n",
       " 'disgraced',\n",
       " 'loves',\n",
       " 'syrupy',\n",
       " 'interviewing',\n",
       " 'primary',\n",
       " 'decaying',\n",
       " 'gwyneth',\n",
       " 'clumsy',\n",
       " 'fellow',\n",
       " 'florence',\n",
       " 'wound',\n",
       " 'recreating',\n",
       " 'unknown',\n",
       " 'slam',\n",
       " 'mcconaughey',\n",
       " 'advance',\n",
       " 'lock',\n",
       " 'kutcher',\n",
       " 'glitches',\n",
       " 'offices',\n",
       " 'armstrong',\n",
       " 'monty',\n",
       " 'jayston',\n",
       " 'royale',\n",
       " 'ultimate',\n",
       " 'those',\n",
       " 'resolved',\n",
       " 'gladly',\n",
       " 'dante',\n",
       " 'distract',\n",
       " 'hiding',\n",
       " 'gratitude',\n",
       " 'cleverness',\n",
       " 'insects',\n",
       " 'cotten',\n",
       " 'tomatoes',\n",
       " 'sade',\n",
       " 'room',\n",
       " 'heighten',\n",
       " 'feldman',\n",
       " 'defense',\n",
       " 'interesting',\n",
       " 'corman',\n",
       " 'astonished',\n",
       " 'pittsburgh',\n",
       " 'better',\n",
       " 'enthusiast',\n",
       " 'vanessa',\n",
       " 'extraordinary',\n",
       " 'dexter',\n",
       " 'yee',\n",
       " 'hendrix',\n",
       " 'lookalike',\n",
       " 'handing',\n",
       " 'bordering',\n",
       " 'coloring',\n",
       " 'modesty',\n",
       " 'producers',\n",
       " 'lose',\n",
       " 'effects',\n",
       " 'typically',\n",
       " 'bliss',\n",
       " 'explicitly',\n",
       " 'spin',\n",
       " 'wealthy',\n",
       " 'conceivable',\n",
       " 'unwelcome',\n",
       " 'outset',\n",
       " 'column',\n",
       " 'orphans',\n",
       " 'janeane',\n",
       " 'earlier',\n",
       " 'outlet',\n",
       " 'guys',\n",
       " 'recall',\n",
       " 'grasp',\n",
       " 'lyric',\n",
       " 'bubblegum',\n",
       " 'shoot',\n",
       " 'http',\n",
       " 'gypo',\n",
       " 'matched',\n",
       " 'seek',\n",
       " 'touched',\n",
       " 'relations',\n",
       " 'concocted',\n",
       " 'padded',\n",
       " 'tire',\n",
       " 'boyfriends',\n",
       " 'running',\n",
       " 'gardenia',\n",
       " 'develop',\n",
       " 'dare',\n",
       " 'nora',\n",
       " 'britney',\n",
       " 'unnecessary',\n",
       " 'challenges',\n",
       " 'outdoors',\n",
       " 'extent',\n",
       " 'gilligan',\n",
       " 'mangled',\n",
       " 'muck',\n",
       " 'chevy',\n",
       " 'crosses',\n",
       " 'meantime',\n",
       " 'mace',\n",
       " 'commentator',\n",
       " 'beautifully',\n",
       " 'saints',\n",
       " 'beating',\n",
       " 'um',\n",
       " 'demand',\n",
       " 'inches',\n",
       " 'everett',\n",
       " 'vonnegut',\n",
       " 'quoted',\n",
       " 'overuse',\n",
       " 'promise',\n",
       " 'accidentally',\n",
       " 'aloud',\n",
       " 'customer',\n",
       " 'sentimentality',\n",
       " 'indian',\n",
       " 'alert',\n",
       " 'extra',\n",
       " 'dopey',\n",
       " 'ambiguity',\n",
       " 'did',\n",
       " 'boone',\n",
       " 'cheesiest',\n",
       " 'woronov',\n",
       " 'reputation',\n",
       " 'insist',\n",
       " 'philadelphia',\n",
       " 'numbingly',\n",
       " 'laughable',\n",
       " 'hammy',\n",
       " 'conceit',\n",
       " 'melbourne',\n",
       " 'undemanding',\n",
       " 'send',\n",
       " 'gone',\n",
       " 'ali',\n",
       " 'moralistic',\n",
       " 'karyo',\n",
       " 'ol',\n",
       " 'upsets',\n",
       " 'babbling',\n",
       " 'gowns',\n",
       " 'craft',\n",
       " 'wrongly',\n",
       " 'bolts',\n",
       " 'words',\n",
       " 'thompson',\n",
       " 'whipping',\n",
       " 'cheeky',\n",
       " 'epitome',\n",
       " 'starving',\n",
       " 'restored',\n",
       " 'limelight',\n",
       " 'impotent',\n",
       " 'spirit',\n",
       " 'eternal',\n",
       " 'temper',\n",
       " 'unwanted',\n",
       " 'colony',\n",
       " 'belgium',\n",
       " 'macross',\n",
       " 'afternoon',\n",
       " 'rocket',\n",
       " 'hari',\n",
       " 'ulterior',\n",
       " 'courage',\n",
       " 'quincy',\n",
       " 'basil',\n",
       " 'aman',\n",
       " 'acknowledge',\n",
       " 'winkler',\n",
       " 'pattern',\n",
       " 'helicopter',\n",
       " 'cosmo',\n",
       " 'alonzo',\n",
       " 'bisexual',\n",
       " 'boss',\n",
       " 'again',\n",
       " 'suspicious',\n",
       " 'skull',\n",
       " 'hungry',\n",
       " 'quigley',\n",
       " 'confident',\n",
       " 'concoction',\n",
       " 'depicted',\n",
       " 'classify',\n",
       " 'shaky',\n",
       " 'physics',\n",
       " 'prejudice',\n",
       " 'alligator',\n",
       " 'cells',\n",
       " 'combination',\n",
       " 'simone',\n",
       " 'competition',\n",
       " 'slowing',\n",
       " 'chicken',\n",
       " 'charges',\n",
       " 'fiorentino',\n",
       " 'invisibility',\n",
       " 'ignorance',\n",
       " 'skits',\n",
       " 'opening',\n",
       " 'booty',\n",
       " 'authenticity',\n",
       " 'tawdry',\n",
       " 'funds',\n",
       " 'manifest',\n",
       " 'chronic',\n",
       " 'glove',\n",
       " 'heartbroken',\n",
       " 'pet',\n",
       " 'purist',\n",
       " 'decent',\n",
       " 'lucrative',\n",
       " 'encountered',\n",
       " 'huge',\n",
       " 'mel',\n",
       " 'swamp',\n",
       " 'mantle',\n",
       " 'select',\n",
       " 'helsing',\n",
       " 'disconcerting',\n",
       " 'aniston',\n",
       " 'totally',\n",
       " 'perfectly',\n",
       " 'underdog',\n",
       " 'persistent',\n",
       " 'tricky',\n",
       " 'ivy',\n",
       " 'massachusetts',\n",
       " 'stefan',\n",
       " 'velvet',\n",
       " 'hardship',\n",
       " 'odds',\n",
       " 'unlucky',\n",
       " 'lamest',\n",
       " 'transferred',\n",
       " 'denise',\n",
       " 'hunk',\n",
       " 'eliminating',\n",
       " 'marital',\n",
       " 'unmotivated',\n",
       " 'lays',\n",
       " 'kooky',\n",
       " 'henri',\n",
       " 'koch',\n",
       " 'seal',\n",
       " 'daffy',\n",
       " 'entranced',\n",
       " 'filmmaker',\n",
       " 'altman',\n",
       " 'treachery',\n",
       " 'hiking',\n",
       " 'inject',\n",
       " 'unsuccessful',\n",
       " 'dolby',\n",
       " 'north',\n",
       " 'needless',\n",
       " 'pilots',\n",
       " 'mrs',\n",
       " 'scenarios',\n",
       " 'babes',\n",
       " 'cent',\n",
       " 'crying',\n",
       " 'derivative',\n",
       " 'bloodless',\n",
       " 'viewed',\n",
       " 'ideal',\n",
       " 'shakespeare',\n",
       " 'dreamer',\n",
       " 'gunshots',\n",
       " 'billion',\n",
       " 'platt',\n",
       " 'bettany',\n",
       " 'executives',\n",
       " 'satan',\n",
       " ...}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16490, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeFeatureVec(train[\"review\"],model,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0.\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    reviewFeatureVecs ={}\n",
    "\n",
    "    counter = 0.\n",
    "    for review in reviews:\n",
    "        if counter % 1000 == 0:\n",
    "            print (\"Review %d of %d\" % (counter, len(reviews)))\n",
    "            \n",
    "        reviewFeatureVecs[int(counter)] = makeFeatureVec(review,model,num_features)\n",
    "        \n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
